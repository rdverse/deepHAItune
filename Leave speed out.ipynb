{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area under curve for finding step frequecny\n",
    "# Find step frequencies for continuous segments\n",
    "# Speed find the running speed in continuous intervals\n",
    "\n",
    "import Data\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras import layers\n",
    "from keras import backend as k\n",
    "import IPython\n",
    "import numpy as np\n",
    "import Data\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import model\n",
    "from model import build_model_CNN\n",
    "from plotter import hist_plotter\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded\n"
     ]
    }
   ],
   "source": [
    "# Get Data Here\n",
    "Features_A, Labels, pIDs = Data.dataset_main(150,50,'Yes')\n",
    "Features_G, Labels, pIDs = Data.dataset_main(150,50,'No')\n",
    "clear_output()\n",
    "print('Dataset Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pIDsUnique = np.unique(pIDs)\n",
    "pIDsUnique\n",
    "pIDsInts = np.arange(len(pIDsUnique))\n",
    "pIDsDict = dict()\n",
    "for i, ID in enumerate(pIDsUnique):\n",
    "    pIDsDict[ID] = pIDsInts[i]\n",
    "\n",
    "pIDsVals = np.array([pIDsDict[ID] for ID in pIDs]).reshape(-1,1)\n",
    "\n",
    "oneHot = OneHotEncoder(sparse=False)\n",
    "pIDsEnc = oneHot.fit_transform(pIDsVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    print('Could not initialize the tensorflow gpu')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def R_Square(y_true, y_pred):\n",
    "\n",
    "    Num = k.sum(k.square(y_true - y_pred))\n",
    "    Denom = k.sum(k.square(y_true - k.mean(y_true)))\n",
    "    R = 1 - Num / (Denom + k.epsilon())\n",
    "    return R\n",
    "\n",
    "\n",
    "def build_model_CNN():\n",
    "    inputA = layers.Input(shape=(3, 150, 1))\n",
    "    modelA = inputA\n",
    "    min_conv1 = 27\n",
    "    max_conv1 = 36\n",
    "    min_conv2 = 36\n",
    "    max_conv2 = 45\n",
    "    modelA = layers.Conv2D(27,\n",
    "                           kernel_size=(3, 3),\n",
    "                           padding='same',\n",
    "                           activation='relu')(inputA)\n",
    "\n",
    "    modelA = layers.Conv2D(45,\n",
    "                           kernel_size=(3, 3),\n",
    "                           padding='same',\n",
    "                           activation='relu')(modelA)\n",
    "\n",
    "    #modelA = layers.Flatten()(modelA)\n",
    "    modelA = layers.GlobalMaxPool2D()(modelA)\n",
    "    inputG = layers.Input(shape=(3, 150, 1))\n",
    "\n",
    "    modelG = inputG\n",
    "\n",
    "    modelG = layers.Conv2D(27,\n",
    "                           kernel_size=(3, 3),\n",
    "                           padding='same',\n",
    "                           activation='relu')(inputG)\n",
    "\n",
    "    modelG = layers.Conv2D(45,\n",
    "                           kernel_size=(3, 3),\n",
    "                           padding='same',\n",
    "                           activation='relu')(modelG)\n",
    "\n",
    "    # model = layers.Dropout(0.4)(model)\n",
    "    #modelG = layers.Flatten()(modelG)\n",
    "    modelG = layers.GlobalMaxPool2D()(modelG)\n",
    "    model = layers.Concatenate()([modelA, modelG])\n",
    "    #   layers.concatenate(modelA,modelG)\n",
    "\n",
    "    #model = layers.Dropout(0.4)(model)\n",
    "\n",
    "    model = layers.Dense(180, activation='relu')(model)\n",
    "\n",
    "    model = layers.Dropout(0.3)(model)\n",
    "\n",
    "    model = layers.Dense(30, activation='relu')(model)\n",
    "\n",
    "    model = layers.Dropout(0.3)(model)\n",
    "\n",
    "    output = layers.Dense(1)(model)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputA, inputG], outputs=output)\n",
    "\n",
    "    optimizer1 = tf.keras.optimizers.RMSprop(1e-3)\n",
    "    # optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "\n",
    "    loss1 = tf.keras.losses.MeanAbsoluteError(name=\"mean_absolute_error\")\n",
    "    \n",
    "    loss2 = tf.keras.losses.MeanAbsoluteError(name=\"mean_absolute_error\")\n",
    "\n",
    "    model.compile(\n",
    "        loss=loss1,  #'mean_absolute_error',\n",
    "        optimizer=optimizer1,\n",
    "        metrics=['mae', 'mape', R_Square])\n",
    "\n",
    "    tf.keras.utils.plot_model(model,\n",
    "                            #  to_file='/home/redev/Pictures/Model.png',\n",
    "                              show_shapes=True)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                 patience=50)\n",
    "\n",
    "reduceLRplateau = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                       min_lr=1e-6,\n",
    "                                                       patience=30,\n",
    "                                                       factor=0.9,\n",
    "                                                       verbose=1)\n",
    "\n",
    "if os.path.isdir('logdir'):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir('logdir')\n",
    "\n",
    "logdir = 'logdir'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3, 150, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 3, 150, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 3, 150, 27)   270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 3, 150, 27)   270         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 3, 150, 45)   10980       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 3, 150, 45)   10980       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 45)           0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 45)           0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 90)           0           global_max_pooling2d[0][0]       \n",
      "                                                                 global_max_pooling2d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 180)          16380       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 180)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           5430        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            31          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,341\n",
      "Trainable params: 44,341\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model_CNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "\n",
    "\n",
    "class EpochDots(tf.keras.callbacks.Callback):\n",
    "  \"\"\"A simple callback that prints a \".\" every epoch, with occasional reports.\n",
    "  Args:\n",
    "    report_every: How many epochs between full reports\n",
    "    dot_every: How many epochs between dots.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, report_every=100, dot_every=1):\n",
    "    self.report_every = report_every\n",
    "    self.dot_every = dot_every\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % self.report_every == 0:\n",
    "      print()\n",
    "      print('Epoch: {:d}, '.format(epoch), end='')\n",
    "      for name, value in sorted(logs.items()):\n",
    "        print('{}:{:0.4f}'.format(name, value), end=',  ')\n",
    "      print()\n",
    "\n",
    "    if epoch % self.dot_every == 0:\n",
    "      print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureAcol = [feature.tostring() for feature in Features_A]\n",
    "FeatureGcol = [feature.tostring() for feature in Features_G]\n",
    "LabelsCol = Labels.ravel()\n",
    "pIDsCol = pIDsVals.ravel()\n",
    "\n",
    "dataDF = pd.DataFrame(list(zip(FeatureAcol, FeatureGcol, LabelsCol, pIDsCol)), columns = ['FeatA', 'FeatG', 'Speed', 'ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupDF = dataDF.groupby(['ID', 'Speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpyArray(arr):\n",
    "    return(np.array([np.frombuffer(feat).reshape(3,150,1) for feat in arr]))\n",
    "\n",
    "\n",
    "def dataParser(dataDF, id, speed):\n",
    "    print(dataDF.shape)\n",
    "    \n",
    "    TrainDF = dataDF[(dataDF['ID']!=id)&(dataDF['Speed']!=speed)]\n",
    "    TestDF = dataDF[(dataDF['ID']==id)&(dataDF['Speed']==speed)]\n",
    "    print(TrainDF.shape)\n",
    "    print(TestDF.shape)\n",
    "        \n",
    "    X_TrainA = get_numpyArray(TrainDF['FeatA'])\n",
    "    X_TrainG = get_numpyArray(TrainDF['FeatG'])\n",
    "    y_TrainSpeed = TrainDF['Speed'].to_numpy().reshape(-1,1)\n",
    "    y_TrainID = TrainDF['ID'].to_numpy()\n",
    "    \n",
    "    X_TestA = get_numpyArray(TestDF['FeatA'])\n",
    "    X_TestG = get_numpyArray(TestDF['FeatG'])\n",
    "    y_TestSpeed = TestDF['Speed'].to_numpy().reshape(-1,1)\n",
    "    y_TestID = TestDF['ID'].to_numpy()\n",
    "    \n",
    "    print(y_TrainSpeed.shape)\n",
    "    print(y_TrainSpeed.shape)\n",
    "    print(X_TrainA.shape)\n",
    "    print(X_TrainG.shape)\n",
    "        \n",
    "    X_TrainA, X_ValA, y_TrainA, y_ValSpeed = train_test_split(X_TrainA, y_TrainSpeed, test_size=0.2, shuffle=True, random_state=90)\n",
    "    X_TrainG, X_ValG, y_TrainG, y_ValSpeed = train_test_split(X_TrainG, y_TrainSpeed, test_size=0.2, shuffle=True, random_state=90)\n",
    "    \n",
    "    return(X_TrainA, X_TrainG, y_TrainA, X_TestA, X_TestG, y_TestSpeed, X_ValA, X_ValG,  y_ValSpeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 736us/step - loss: 0.5097 - mae: 0.5097 - mape: 8.4953 - R_Square: -95771384.0000\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns = ['id', 'speed','loss', 'mae', 'mape', 'r2','me'])\n",
    "from keras import backend as K\n",
    "for id, speed in groupDF.groups:    \n",
    "    X_TrainA, X_TrainG, y_Train, X_TestA, X_TestG, y_Test, X_ValA, X_ValG, y_Val = dataParser(dataDF, id,speed)\n",
    "\n",
    "    hist = model.fit(\n",
    "    [X_TrainA, X_TrainG],\n",
    "    y_Train,\n",
    " #   validation_data=([Features_A, Features_G], Labels),\n",
    "   validation_data=([X_ValA,X_ValG],y_Val),\n",
    "        epochs=200,\n",
    "    verbose=0,\n",
    "    callbacks=[\n",
    "        \n",
    "        EpochDots(report_every=50),\n",
    "    #    reduceLRplateau,\n",
    "        ClearTrainingOutput()\n",
    "    ])\n",
    "\n",
    "    results = [id, speed]\n",
    "    results.extend(model.evaluate([X_TestA, X_TestG], np.array(y_Test)))\n",
    "    results.append(model.predict([X_TestA, X_TestG]).mean())\n",
    "    \n",
    "    results_df.loc[len(results_df)] = results\n",
    "    results=list()\n",
    "    K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['difference'] = results_df['speed']- results_df['me']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32078277441055586"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['mae'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 559us/step - loss: 0.2344 - mae: 0.2344 - mape: 7.3238 - R_Square: -16949208.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2343616634607315, 0.2343616634607315, 7.323801040649414, -16949208.0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.evaluate([X_TestA, X_TestG], np.array(y_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.267229681802918"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(model.predict([X_TestA, X_TestG]), np.array(y_Test).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.drop(columns ='r2').to_csv('leave_one_speed_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>speed</th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>r2</th>\n",
       "      <th>me</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.571972</td>\n",
       "      <td>0.571972</td>\n",
       "      <td>19.065723</td>\n",
       "      <td>-90419904.0</td>\n",
       "      <td>3.571972</td>\n",
       "      <td>-0.571972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.219821</td>\n",
       "      <td>0.219821</td>\n",
       "      <td>6.869399</td>\n",
       "      <td>-16393842.0</td>\n",
       "      <td>3.419821</td>\n",
       "      <td>-0.219821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.231096</td>\n",
       "      <td>0.231096</td>\n",
       "      <td>6.602746</td>\n",
       "      <td>-21935340.0</td>\n",
       "      <td>3.573243</td>\n",
       "      <td>-0.073243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.288492</td>\n",
       "      <td>0.288492</td>\n",
       "      <td>7.212306</td>\n",
       "      <td>-23341392.0</td>\n",
       "      <td>3.770248</td>\n",
       "      <td>0.229752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.510772</td>\n",
       "      <td>0.510772</td>\n",
       "      <td>12.161246</td>\n",
       "      <td>-71306488.0</td>\n",
       "      <td>3.725663</td>\n",
       "      <td>0.474337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  speed      loss       mae       mape          r2        me  difference\n",
       "0  0.0    3.0  0.571972  0.571972  19.065723 -90419904.0  3.571972   -0.571972\n",
       "1  0.0    3.2  0.219821  0.219821   6.869399 -16393842.0  3.419821   -0.219821\n",
       "2  0.0    3.5  0.231096  0.231096   6.602746 -21935340.0  3.573243   -0.073243\n",
       "3  0.0    4.0  0.288492  0.288492   7.212306 -23341392.0  3.770248    0.229752\n",
       "4  0.0    4.2  0.510772  0.510772  12.161246 -71306488.0  3.725663    0.474337"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyHAI",
   "language": "python",
   "name": "pyhai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
