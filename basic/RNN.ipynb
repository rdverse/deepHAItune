{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run model.py\n",
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'untitled_project': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!rm -r logdir\n",
    "!rm -r \"untitled_project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accel\n",
      "18\n",
      "Train Labels shape   : (2577, 1)\n",
      "Train Features shape : (2577, 3, 150, 1)\n",
      "Test labels shape    : (645, 1)\n",
      "Test Features shape  : (645, 3, 150, 1)\n",
      "Gyro\n",
      "18\n",
      "Train Labels shape   : (2577, 1)\n",
      "Train Features shape : (2577, 3, 150, 1)\n",
      "Test labels shape    : (645, 1)\n",
      "Test Features shape  : (645, 3, 150, 1)\n",
      "(2061, 150, 3)\n",
      "(None, 90)\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 150, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1D_A1 (Conv1D)              (None, 150, 45)      720         input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 150, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 150, 45)      180         conv1D_A1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1D_G1 (Conv1D)              (None, 150, 45)      720         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 150, 45)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 150, 45)      180         conv1D_G1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1D_A2 (Conv1D)              (None, 150, 45)      10170       leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 150, 45)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 150, 45)      180         conv1D_A2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1D_G2 (Conv1D)              (None, 150, 45)      10170       leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 150, 45)      0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 150, 45)      180         conv1D_G2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 150, 45)      0           leaky_re_lu_30[0][0]             \n",
      "                                                                 leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 150, 45)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 150, 45)      0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 150, 45)      0           leaky_re_lu_33[0][0]             \n",
      "                                                                 leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 45)           0           leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_14 (Global (None, 45)           0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 90)           0           global_max_pooling1d_13[0][0]    \n",
      "                                                                 global_max_pooling1d_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 90, 1)        0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_13 (LSTM)                  (None, 90, 90)       33120       reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  (None, 90, 90)       65160       lstm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 90, 90)       0           lstm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 90, 180)      16380       dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 90, 180)      0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 90, 30)       5430        dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 90, 30)       0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 90, 1)        31          dropout_21[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 142,621\n",
      "Trainable params: 142,261\n",
      "Non-trainable params: 360\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/2000\n",
      "65/65 [==============================] - 8s 120ms/step - loss: 1.6996 - mae: 1.6996 - mape: 36.3663 - R_Square: -376.5971 - val_loss: 0.7428 - val_mae: 0.7428 - val_mape: 14.8033 - val_R_Square: -77.8326\n",
      "Epoch 2/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 1.0355 - mae: 1.0355 - mape: 22.1398 - R_Square: -133.4987 - val_loss: 0.5431 - val_mae: 0.5431 - val_mape: 11.5307 - val_R_Square: -36.8654\n",
      "Epoch 3/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.9609 - mae: 0.9609 - mape: 20.5770 - R_Square: -114.8100 - val_loss: 0.8009 - val_mae: 0.8009 - val_mape: 15.4429 - val_R_Square: -81.4047\n",
      "Epoch 4/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.9416 - mae: 0.9416 - mape: 20.0716 - R_Square: -110.8809 - val_loss: 0.6372 - val_mae: 0.6372 - val_mape: 12.6590 - val_R_Square: -52.2076\n",
      "Epoch 5/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.9080 - mae: 0.9080 - mape: 19.4258 - R_Square: -103.3218 - val_loss: 0.6629 - val_mae: 0.6629 - val_mape: 13.0227 - val_R_Square: -56.4166\n",
      "Epoch 6/2000\n",
      "65/65 [==============================] - 8s 116ms/step - loss: 0.8886 - mae: 0.8886 - mape: 18.9926 - R_Square: -100.0889 - val_loss: 0.6818 - val_mae: 0.6818 - val_mape: 13.3117 - val_R_Square: -58.9908\n",
      "Epoch 7/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.8752 - mae: 0.8752 - mape: 18.7065 - R_Square: -96.7619 - val_loss: 0.7836 - val_mae: 0.7836 - val_mape: 15.1430 - val_R_Square: -76.0153\n",
      "Epoch 8/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 2.7529 - mae: 2.7529 - mape: 72.1022 - R_Square: -8665546.0000 - val_loss: 0.6452 - val_mae: 0.6452 - val_mape: 13.5404 - val_R_Square: -55.2756\n",
      "Epoch 9/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.9510 - mae: 0.9510 - mape: 20.4412 - R_Square: -114.6543 - val_loss: 0.7242 - val_mae: 0.7242 - val_mape: 14.3190 - val_R_Square: -68.8125\n",
      "Epoch 10/2000\n",
      "65/65 [==============================] - 7s 112ms/step - loss: 0.9206 - mae: 0.9206 - mape: 19.7605 - R_Square: -107.0598 - val_loss: 0.5699 - val_mae: 0.5699 - val_mape: 11.8854 - val_R_Square: -42.6176\n",
      "Epoch 11/2000\n",
      "65/65 [==============================] - 7s 112ms/step - loss: 0.8968 - mae: 0.8968 - mape: 19.2147 - R_Square: -100.1584 - val_loss: 0.7389 - val_mae: 0.7389 - val_mape: 14.4131 - val_R_Square: -70.5884\n",
      "Epoch 12/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.8939 - mae: 0.8939 - mape: 19.0880 - R_Square: -101.8877 - val_loss: 0.5603 - val_mae: 0.5603 - val_mape: 11.4690 - val_R_Square: -40.5019\n",
      "Epoch 13/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.8608 - mae: 0.8608 - mape: 18.3846 - R_Square: -91.8497 - val_loss: 0.5084 - val_mae: 0.5084 - val_mape: 10.7249 - val_R_Square: -31.9035\n",
      "Epoch 14/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.8591 - mae: 0.8591 - mape: 18.3465 - R_Square: -92.1393 - val_loss: 0.5163 - val_mae: 0.5163 - val_mape: 10.7308 - val_R_Square: -32.9913\n",
      "Epoch 15/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.8479 - mae: 0.8479 - mape: 18.1389 - R_Square: -90.3547 - val_loss: 0.6346 - val_mae: 0.6346 - val_mape: 12.5730 - val_R_Square: -51.5388\n",
      "Epoch 16/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.8343 - mae: 0.8343 - mape: 17.8072 - R_Square: -87.3737 - val_loss: 0.6550 - val_mae: 0.6550 - val_mape: 12.8409 - val_R_Square: -55.2460\n",
      "Epoch 17/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.8260 - mae: 0.8260 - mape: 17.5881 - R_Square: -86.4706 - val_loss: 0.5371 - val_mae: 0.5371 - val_mape: 10.9224 - val_R_Square: -36.0552\n",
      "Epoch 18/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.8142 - mae: 0.8142 - mape: 17.3568 - R_Square: -83.2258 - val_loss: 0.5128 - val_mae: 0.5128 - val_mape: 10.6732 - val_R_Square: -32.1156\n",
      "Epoch 19/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.8045 - mae: 0.8045 - mape: 17.1686 - R_Square: -80.6917 - val_loss: 0.4595 - val_mae: 0.4595 - val_mape: 9.9629 - val_R_Square: -24.5753\n",
      "Epoch 20/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.8021 - mae: 0.8021 - mape: 17.1231 - R_Square: -81.0366 - val_loss: 0.5295 - val_mae: 0.5295 - val_mape: 10.7888 - val_R_Square: -34.7712\n",
      "Epoch 21/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.7947 - mae: 0.7947 - mape: 16.9511 - R_Square: -80.1462 - val_loss: 0.4687 - val_mae: 0.4687 - val_mape: 9.9414 - val_R_Square: -25.8585\n",
      "Epoch 22/2000\n",
      "65/65 [==============================] - 7s 112ms/step - loss: 0.7855 - mae: 0.7855 - mape: 16.7366 - R_Square: -76.6442 - val_loss: 0.5269 - val_mae: 0.5269 - val_mape: 10.6321 - val_R_Square: -34.9155\n",
      "Epoch 23/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.7761 - mae: 0.7761 - mape: 16.5557 - R_Square: -75.4516 - val_loss: 0.4747 - val_mae: 0.4747 - val_mape: 9.8310 - val_R_Square: -27.4855\n",
      "Epoch 24/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.7734 - mae: 0.7734 - mape: 16.5081 - R_Square: -74.7110 - val_loss: 0.4868 - val_mae: 0.4868 - val_mape: 10.0215 - val_R_Square: -28.9988\n",
      "Epoch 25/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.7569 - mae: 0.7569 - mape: 16.1099 - R_Square: -71.2433 - val_loss: 0.5275 - val_mae: 0.5275 - val_mape: 10.5785 - val_R_Square: -35.2330\n",
      "Epoch 26/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.7463 - mae: 0.7463 - mape: 15.9154 - R_Square: -70.2851 - val_loss: 0.5292 - val_mae: 0.5292 - val_mape: 10.6382 - val_R_Square: -35.3635\n",
      "Epoch 27/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.7466 - mae: 0.7466 - mape: 15.9235 - R_Square: -70.0856 - val_loss: 0.5812 - val_mae: 0.5812 - val_mape: 11.4608 - val_R_Square: -42.9972\n",
      "Epoch 28/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.7475 - mae: 0.7475 - mape: 15.8646 - R_Square: -69.9714 - val_loss: 0.4402 - val_mae: 0.4402 - val_mape: 9.2371 - val_R_Square: -23.4124\n",
      "Epoch 29/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.7446 - mae: 0.7446 - mape: 15.8576 - R_Square: -70.8151 - val_loss: 0.4841 - val_mae: 0.4841 - val_mape: 9.8722 - val_R_Square: -28.9730\n",
      "Epoch 30/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.7253 - mae: 0.7253 - mape: 15.4299 - R_Square: -66.5000 - val_loss: 0.5502 - val_mae: 0.5502 - val_mape: 10.8916 - val_R_Square: -38.4202\n",
      "Epoch 31/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.7192 - mae: 0.7192 - mape: 15.2903 - R_Square: -65.1454 - val_loss: 0.4612 - val_mae: 0.4612 - val_mape: 9.6721 - val_R_Square: -25.5400\n",
      "Epoch 32/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.7069 - mae: 0.7069 - mape: 15.0602 - R_Square: -62.9185 - val_loss: 0.4859 - val_mae: 0.4859 - val_mape: 9.8048 - val_R_Square: -29.9503\n",
      "Epoch 33/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.7149 - mae: 0.7149 - mape: 15.1701 - R_Square: -64.7859 - val_loss: 0.5502 - val_mae: 0.5502 - val_mape: 10.8496 - val_R_Square: -39.0749\n",
      "Epoch 34/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.7062 - mae: 0.7062 - mape: 15.0061 - R_Square: -62.9065 - val_loss: 0.4945 - val_mae: 0.4945 - val_mape: 9.9056 - val_R_Square: -31.4372\n",
      "Epoch 35/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.6948 - mae: 0.6948 - mape: 14.7220 - R_Square: -61.0802 - val_loss: 0.4513 - val_mae: 0.4513 - val_mape: 9.2091 - val_R_Square: -25.9055\n",
      "Epoch 36/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.6857 - mae: 0.6857 - mape: 14.5594 - R_Square: -59.5953 - val_loss: 0.4853 - val_mae: 0.4853 - val_mape: 9.7219 - val_R_Square: -30.2215\n",
      "Epoch 37/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.6896 - mae: 0.6896 - mape: 14.6463 - R_Square: -60.4077 - val_loss: 0.5541 - val_mae: 0.5541 - val_mape: 10.8842 - val_R_Square: -39.5891\n",
      "Epoch 38/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.6767 - mae: 0.6767 - mape: 14.3206 - R_Square: -58.6047 - val_loss: 0.4616 - val_mae: 0.4616 - val_mape: 9.3219 - val_R_Square: -27.5439\n",
      "Epoch 39/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.6646 - mae: 0.6646 - mape: 14.0707 - R_Square: -56.4985 - val_loss: 0.4708 - val_mae: 0.4708 - val_mape: 9.4191 - val_R_Square: -28.6743\n",
      "Epoch 40/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.6607 - mae: 0.6607 - mape: 14.0264 - R_Square: -54.9801 - val_loss: 0.5161 - val_mae: 0.5161 - val_mape: 10.2484 - val_R_Square: -34.3347\n",
      "Epoch 41/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.6553 - mae: 0.6553 - mape: 13.8715 - R_Square: -54.4884 - val_loss: 0.5379 - val_mae: 0.5379 - val_mape: 10.5993 - val_R_Square: -37.2705\n",
      "Epoch 42/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.6397 - mae: 0.6397 - mape: 13.5074 - R_Square: -53.1059 - val_loss: 0.4530 - val_mae: 0.4530 - val_mape: 9.0738 - val_R_Square: -26.8376\n",
      "Epoch 43/2000\n",
      "65/65 [==============================] - 8s 117ms/step - loss: 0.6442 - mae: 0.6442 - mape: 13.6305 - R_Square: -53.8845 - val_loss: 0.4302 - val_mae: 0.4302 - val_mape: 8.7694 - val_R_Square: -23.9869\n",
      "Epoch 44/2000\n",
      "65/65 [==============================] - 8s 118ms/step - loss: 0.6324 - mae: 0.6324 - mape: 13.3511 - R_Square: -51.6223 - val_loss: 0.4250 - val_mae: 0.4250 - val_mape: 8.6556 - val_R_Square: -23.3915\n",
      "Epoch 45/2000\n",
      "65/65 [==============================] - 8s 116ms/step - loss: 0.6202 - mae: 0.6202 - mape: 13.1194 - R_Square: -50.5534 - val_loss: 0.4630 - val_mae: 0.4630 - val_mape: 9.2486 - val_R_Square: -27.9457\n",
      "Epoch 46/2000\n",
      "65/65 [==============================] - 8s 117ms/step - loss: 0.6706 - mae: 0.6706 - mape: 14.1640 - R_Square: -960.2722 - val_loss: 0.5194 - val_mae: 0.5194 - val_mape: 10.9429 - val_R_Square: -33.7285\n",
      "Epoch 47/2000\n",
      "65/65 [==============================] - 8s 116ms/step - loss: 0.6805 - mae: 0.6805 - mape: 14.4114 - R_Square: -59.5846 - val_loss: 0.4636 - val_mae: 0.4636 - val_mape: 9.9906 - val_R_Square: -26.7987\n",
      "Epoch 48/2000\n",
      "65/65 [==============================] - 7s 115ms/step - loss: 0.6609 - mae: 0.6609 - mape: 14.0204 - R_Square: -55.6013 - val_loss: 0.4745 - val_mae: 0.4745 - val_mape: 9.7957 - val_R_Square: -28.7029\n",
      "Epoch 49/2000\n",
      "65/65 [==============================] - 8s 116ms/step - loss: 0.6567 - mae: 0.6567 - mape: 13.9016 - R_Square: -54.8241 - val_loss: 0.5431 - val_mae: 0.5431 - val_mape: 10.7734 - val_R_Square: -38.1263\n",
      "Epoch 50/2000\n",
      "65/65 [==============================] - 8s 115ms/step - loss: 0.6457 - mae: 0.6457 - mape: 13.6263 - R_Square: -53.7972 - val_loss: 0.5165 - val_mae: 0.5165 - val_mape: 10.3707 - val_R_Square: -33.9365\n",
      "Epoch 51/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.6330 - mae: 0.6330 - mape: 13.3455 - R_Square: -50.9830 - val_loss: 0.4707 - val_mae: 0.4707 - val_mape: 9.6695 - val_R_Square: -27.9736\n",
      "Epoch 52/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.6240 - mae: 0.6240 - mape: 13.1687 - R_Square: -50.9444 - val_loss: 0.4601 - val_mae: 0.4601 - val_mape: 9.4824 - val_R_Square: -26.1767\n",
      "Epoch 53/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.6209 - mae: 0.6209 - mape: 13.1147 - R_Square: -49.4121 - val_loss: 0.4971 - val_mae: 0.4971 - val_mape: 10.0137 - val_R_Square: -31.4015\n",
      "Epoch 54/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.6080 - mae: 0.6080 - mape: 12.7673 - R_Square: -47.0332 - val_loss: 0.4691 - val_mae: 0.4691 - val_mape: 9.5952 - val_R_Square: -27.3162\n",
      "Epoch 55/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.6104 - mae: 0.6104 - mape: 12.8971 - R_Square: -47.1314 - val_loss: 0.5202 - val_mae: 0.5202 - val_mape: 10.7355 - val_R_Square: -34.5305\n",
      "Epoch 56/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.6015 - mae: 0.6015 - mape: 12.6838 - R_Square: -46.8186 - val_loss: 0.4776 - val_mae: 0.4776 - val_mape: 9.6807 - val_R_Square: -28.7453\n",
      "Epoch 57/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.5878 - mae: 0.5878 - mape: 12.3626 - R_Square: -44.6915 - val_loss: 0.4879 - val_mae: 0.4879 - val_mape: 9.8245 - val_R_Square: -30.0647\n",
      "Epoch 58/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.5879 - mae: 0.5879 - mape: 12.3728 - R_Square: -44.4677 - val_loss: 0.4580 - val_mae: 0.4580 - val_mape: 9.3463 - val_R_Square: -25.8861\n",
      "Epoch 59/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.5838 - mae: 0.5838 - mape: 12.3158 - R_Square: -44.2321 - val_loss: 0.4896 - val_mae: 0.4896 - val_mape: 9.8249 - val_R_Square: -30.6681\n",
      "Epoch 60/2000\n",
      "65/65 [==============================] - 8s 116ms/step - loss: 0.5742 - mae: 0.5742 - mape: 12.0291 - R_Square: -42.7642 - val_loss: 0.4393 - val_mae: 0.4393 - val_mape: 8.9862 - val_R_Square: -24.2709\n",
      "Epoch 61/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.5730 - mae: 0.5730 - mape: 12.0140 - R_Square: -44.3212 - val_loss: 0.4583 - val_mae: 0.4583 - val_mape: 9.2510 - val_R_Square: -26.9836\n",
      "Epoch 62/2000\n",
      "65/65 [==============================] - 7s 115ms/step - loss: 0.5682 - mae: 0.5682 - mape: 11.9367 - R_Square: -41.7688 - val_loss: 0.4527 - val_mae: 0.4527 - val_mape: 9.2923 - val_R_Square: -25.3994\n",
      "Epoch 63/2000\n",
      "65/65 [==============================] - 8s 118ms/step - loss: 0.5685 - mae: 0.5685 - mape: 11.9550 - R_Square: -41.7924 - val_loss: 0.4312 - val_mae: 0.4312 - val_mape: 8.7850 - val_R_Square: -23.5263\n",
      "Epoch 64/2000\n",
      "65/65 [==============================] - 8s 117ms/step - loss: 0.5558 - mae: 0.5558 - mape: 11.6870 - R_Square: -39.5397 - val_loss: 0.4740 - val_mae: 0.4740 - val_mape: 9.4283 - val_R_Square: -29.3335\n",
      "Epoch 65/2000\n",
      "65/65 [==============================] - 8s 116ms/step - loss: 0.5587 - mae: 0.5587 - mape: 11.7250 - R_Square: -40.0910 - val_loss: 0.5392 - val_mae: 0.5392 - val_mape: 10.6297 - val_R_Square: -37.0684\n",
      "Epoch 66/2000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.5455 - mae: 0.5455 - mape: 11.4379 - R_Square: -38.9598 - val_loss: 0.4759 - val_mae: 0.4759 - val_mape: 9.4857 - val_R_Square: -29.6938\n",
      "Epoch 67/2000\n",
      "65/65 [==============================] - 7s 112ms/step - loss: 0.5403 - mae: 0.5403 - mape: 11.3045 - R_Square: -38.5836 - val_loss: 0.4421 - val_mae: 0.4421 - val_mape: 8.8889 - val_R_Square: -25.6686\n",
      "Epoch 68/2000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.5400 - mae: 0.5400 - mape: 11.3190 - R_Square: -37.9886 - val_loss: 0.4508 - val_mae: 0.4508 - val_mape: 9.0680 - val_R_Square: -26.3691\n",
      "Epoch 69/2000\n",
      "65/65 [==============================] - 7s 112ms/step - loss: 0.5378 - mae: 0.5378 - mape: 11.2859 - R_Square: -37.9898 - val_loss: 0.4812 - val_mae: 0.4812 - val_mape: 9.5801 - val_R_Square: -30.1258\n",
      "Epoch 70/2000\n",
      "65/65 [==============================] - 7s 112ms/step - loss: 0.5338 - mae: 0.5338 - mape: 11.1753 - R_Square: -37.1964 - val_loss: 0.5633 - val_mae: 0.5633 - val_mape: 10.9989 - val_R_Square: -40.6630\n",
      "Epoch 71/2000\n",
      "65/65 [==============================] - 7s 112ms/step - loss: 0.5381 - mae: 0.5381 - mape: 11.2588 - R_Square: -37.3883 - val_loss: 0.4096 - val_mae: 0.4096 - val_mape: 8.3893 - val_R_Square: -21.7250\n",
      "Epoch 72/2000\n",
      "65/65 [==============================] - 7s 112ms/step - loss: 0.5208 - mae: 0.5208 - mape: 10.9105 - R_Square: -35.6885 - val_loss: 0.4048 - val_mae: 0.4048 - val_mape: 8.1983 - val_R_Square: -21.3667\n",
      "Epoch 73/2000\n",
      "42/65 [==================>...........] - ETA: 2s - loss: 0.5198 - mae: 0.5198 - mape: 10.9048 - R_Square: -34.8202"
     ]
    }
   ],
   "source": [
    "%run final_model_RNN.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13842), started 0:03:44 ago. (Use '!kill 13842' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-556d3865afce1361\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-556d3865afce1361\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorboard\n",
    "\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-67e726a36d102005\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-67e726a36d102005\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run model.py\n",
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4)\n",
      "(32, 10, 4)\n",
      "(32, 4)\n",
      "(32, 4)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.random.normal([32, 10, 8])\n",
    "lstm = tf.keras.layers.LSTM(4)\n",
    "output = lstm(inputs)\n",
    "print(output.shape)\n",
    "lstm = tf.keras.layers.LSTM(4, return_sequences=True, return_state=True)\n",
    "whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n",
    "print(whole_seq_output.shape)\n",
    "print(final_memory_state.shape)\n",
    "print(final_carry_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 10, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhai",
   "language": "python",
   "name": "pyhai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
