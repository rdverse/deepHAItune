{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the effect of classification on the speed data\n",
    "\n",
    "<b>Intuition :</b> Literature in speed detection suggests that usage of hybrid models increases precision of the model. But these classifications are made strictly between slower and faster speeds or walking and runnning speeds. So we first test the effectiveness of classifier to split the speeds between slower and higher speeds. Then we try to see if there is any improvement in the precision in speed detection using the classifier with the highest accuracy. NOte: The regression algorithm used here will be RandomForest as the best regression model was found to be random forests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataBuilder import DataBuilder\n",
    "import ClassEvaluator\n",
    "\n",
    "import skSVM\n",
    "import skRandomForestClassifier\n",
    "import skKNeighborsClassifier\n",
    "import skLogisticRegression\n",
    "\n",
    "import numpy as np\n",
    "import importlib,sys \n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel(name):\n",
    "    importlib.reload(sys.modules[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:21<00:00,  7.02s/it]\n"
     ]
    }
   ],
   "source": [
    "dataBuilder = DataBuilder(heuristic = False, applyFilter =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [4, 4.5, 5.5, 5, 6]\n",
    "PCA = [ True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = SVC()\n",
    "#clf = RandomForestClassifier(n_estimators =250, max_depth = 60)\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "X_Train, y_Train, X_Test, y_Test = dataBuilder.confs['data1']['conf1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Tr = [0 if y<4.2 else 1 for y in y_Train]\n",
    "y_Te = [0 if y<4.2 else 1 for y in y_Test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_Train, y_Tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.93       579\n",
      "           1       0.93      0.99      0.96       970\n",
      "\n",
      "    accuracy                           0.95      1549\n",
      "   macro avg       0.96      0.93      0.94      1549\n",
      "weighted avg       0.95      0.95      0.95      1549\n",
      "\n",
      "94.7062621045836%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 1283, 1: 2330})"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(classification_report(preds, y_Te))\n",
    "print('{}%'.format(accuracy_score(preds, y_Te)*100))\n",
    "from collections import Counter\n",
    "Counter(y_Tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel('skSVM')\n",
    "rel('ClassEvaluator')\n",
    "rel('hyperparameters')\n",
    "\n",
    "for applyPCA in PCA:\n",
    "    skSVMClassifier = skSVM.skSVM(applyPCA)\n",
    "    model = skSVMClassifier.model\n",
    "    name = skSVMClassifier.name\n",
    "    for dataKey, confDict in dataBuilder.confs.items():\n",
    "        for confKey, confData in confDict.items():\n",
    "            for split_value in splits:\n",
    "                print(confData[0].shape)\n",
    "                evaluator  = ClassEvaluator.Evaluator(name, dataKey, model, confKey, confData, split_value)\n",
    "                evaluator.train_model()\n",
    "                evaluator.store()\n",
    "clear_output()\n",
    "print('Grid Search completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel('skRandomForestClassifier')\n",
    "rel('ClassEvaluator')\n",
    "rel('hyperparameters')\n",
    "\n",
    "for applyPCA in PCA:\n",
    "    skRFC = skRandomForestClassifier.skRandomForestClassifier(applyPCA)\n",
    "    model = skRFC.model\n",
    "    name = skRFC.name\n",
    "    \n",
    "    for dataKey, confDict in dataBuilder.confs.items():\n",
    "        for confKey, confData in confDict.items():\n",
    "            for split_value in splits:\n",
    "                evaluator  = ClassEvaluator.Evaluator(name, dataKey, model, confKey, confData, split_value)\n",
    "                evaluator.train_model()\n",
    "                evaluator.store()        \n",
    "            \n",
    "clear_output()\n",
    "print('Grid Search completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel('skKNeighborsClassifier')\n",
    "rel('ClassEvaluator')\n",
    "rel('hyperparameters')\n",
    "\n",
    "for applyPCA in PCA:\n",
    "    skKNNC = skKNeighborsClassifier.skKNeighborsClassifier(applyPCA)\n",
    "    model = skKNNC.model\n",
    "    name = skKNNC.name\n",
    "\n",
    "    for dataKey, confDict in dataBuilder.confs.items():\n",
    "        for confKey, confData in confDict.items():\n",
    "            for split_value in splits:\n",
    "                print(confData[0].shape)\n",
    "                evaluator  = ClassEvaluator.Evaluator(name, dataKey, model, confKey, confData, split_value)\n",
    "                evaluator.train_model()\n",
    "                evaluator.store()  \n",
    "            \n",
    "clear_output()\n",
    "print('Grid Search completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel('skLogisticRegression')\n",
    "rel('ClassEvaluator')\n",
    "rel('hyperparameters')\n",
    "\n",
    "for applyPCA in PCA:\n",
    "    skLogReg = skLogisticRegression.skLogisticRegression(applyPCA)\n",
    "    model = skLogReg.model\n",
    "    name = skLogReg.name\n",
    "\n",
    "    for dataKey, confDict in dataBuilder.confs.items():\n",
    "        for confKey, confData in confDict.items():\n",
    "            for split_value in splits:\n",
    "                print(confData[0].shape)\n",
    "                evaluator  = ClassEvaluator.Evaluator(name, dataKey, model, confKey, confData, split_value)\n",
    "                evaluator.train_model()\n",
    "                evaluator.store()  \n",
    "            \n",
    "clear_output()\n",
    "print('Grid Search completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with Heuristic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accel\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/redev/Quanta/deepHAItune/Machine Learning/Heuristics.py:63: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  heuristicFeature = np.hstack(heuristics.values())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Labels shape   : (1121, 1)\n",
      "Train Features shape : (1121, 39)\n",
      "Test labels shape    : (481, 1)\n",
      "Test Features shape  : (481, 39)\n",
      "Gyro\n",
      "9\n",
      "Train Labels shape   : (1121, 1)\n",
      "Train Features shape : (1121, 39)\n",
      "Test labels shape    : (481, 1)\n",
      "Test Features shape  : (481, 39)\n"
     ]
    }
   ],
   "source": [
    "from Heuristics import *\n",
    "import Heuristics\n",
    "\n",
    "import MLData\n",
    "rel('Heuristics')\n",
    "rel('MLData')\n",
    "\n",
    "X_TrainA, y_Train, X_TestA, y_Test = MLData.dataset_main(150,0,'Yes','no',True )\n",
    "X_TrainG, y_TrainG, X_TestG, y_TestG = MLData.dataset_main(150,0,'No','no',True )\n",
    "\n",
    "X_Train = np.hstack((X_TrainA, X_TrainG))\n",
    "X_TestG = np.hstack((X_TestA, X_TestG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter =10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_Train, y_Tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = logreg.predict(X_TestG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8981288981288982"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(preds, y_Te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TestG[l] = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyHAI",
   "language": "python",
   "name": "pyhai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
